"Mistake-proofing" our codeI was just reading a portion of Mary and Tom Poppendieck's book "Implementing Lean Software Development" where it goes into a section called "Zero Inspection". Here's a short excerpt:"A properly mistake-proofed system will not need inspection. My video cable is an example of mistake-proofing. I can't plug a monitor cable into a computer or video projector upside down because the cable and plug are keyed. So I don't need someone to inspect that I plugged the cable in correctly, because it's impossible to get it wrong. Mistake proofing assumes that any mistake that can be made will eventually be made, so take the time at the start to make the mistake impossible."This is something that I know, at my company, we could get better at. For example, we don't use much encapsulation within our classes. We use an "anemic object model" where the logic is outside of the class. Some ideas for fool-proofing, that would be great to introduce, are:* Throw exceptions in code so that things blow up in a big way, instead of silently failing* Make access to class members as restricted as possible, adding public mutators only where absolutely necessary. That way, devs who use the class cannot put the class into an unstable state.* Using class constructors to get all the required data a class needs, thus never allowing a class to be partially initialized with partial data, such as what may happen if the developer is allowed to set up the class by setting public mutators* Hiding lower-level components within an encapsulated class so that the developer doesn't get confused and try to use a low-level interface instead of the higher level oneWhat experiences have others had along this line of thinking? Are there other ways to mistake-proof code? And how best to get others on-board?13 days agoLike CommentFollow Flag MoreBrian H. M., David H. and 6 others like this25 comments • Jump to most recent comments DavidDavid H. • In my opinion, "Mistake-Proofed Code" is akin to code that follows good design patterns. I'm a big fan of the anemic object model, and used to be of the constructor model for my POCOs also, but later forwent having constructors on POCOs in exchange for being able to map them via ORMs such as Dapper. Mistake-proofing code comes with experience and enforcement of patterns. For example, in a system where inversion of control is properly used, testing is very easy. At that point, Test Driven Design can help to create mistake-proofed code. Another classic way is to, where-ever possible, create immutable (read-only) objects. Not only does this prevent mutated state, but it avoids a WORLD of thread-safety issues and can even allow you to create some objects as structs for efficiency purposes. I'm a big fan of, where-ever possible on non-POCOs, having constructor injection. In fact, I rarely use Properties at all on my logic classes. The constructor then does sanity checks such as null checks and value validity checks, and throws the appropriate exception. I don't catch exceptions much because if my system has failed that catastrophically, there's not much I can do about it anyway in terms of catch code. Finally, the anemic model rules when you're doing serialization/deserialization since your object is light-weight and smaller thus serializes a lot faster. I don't have any specific advice on this topic but a good understanding and deployment of design patterns, programming to the interface, and inversion of control definitely help to make code "mistake proof".13 days ago ZijianZijian H. • According to the descriptions, "Mistake-proofing" is just just about defensive programming along with OOD and some design patterns, well documented in book "Code Complete".However, I think "Mistake-proofing" the name may be a bit misleading, since it might be interpreted as "no mistake made" at some degree.If they are the same thing, I would prefer defensive programming.12 days ago PeterPeter S. • While mistake proofed code is a great idea, it's also potentially a very bad idea. why? Well it depends on the person doing the mistake proofing. Let me give you an example. At a previous job where I was contracting, there was a permanent member of staff (We'll call him Jeff) who's job was to take any code produced on the development machines, build it on the staging systems and test it. He was then supposed to feed these results back to the dev team, with a report on the state of the build. Why where things done this way, well because the dev boxes where not a replica of the live environment , and the staging platform was, more so the staging platform was actually hooked into the web farm, and when switched on one in every 10 live requests would be directed to it, which was enough to be able to see if it stood up, but not so much that 1000's of complaints would be seen if it went disastrous. anyway... back to 'Jeff' Jeff was pretty much a maintenance programmer, not a daft person, but still lacked a certain amount of skill that the core dev team (Built from consultants & seniors and other professional devs) one of his duties when proofing the code builds was that if a bug was quick to fix, and could be "Made to go away" with out sending it back to the dev team, then he was to do this... Effectively he was asked to nullify our mistakes. Now 'Jeff' was also keen to impress his bosses, given that he was a permanent member of the team and all that so he effectively "Mistake proofed" a lot of mistakes. Now I don't in any way want to undermine his motivation, the guy was a very keen team player, but his methods left a huge amount to be desired. Jeff's fix rate was astounding when I first saw it, he was fixing a huge amount of bugs, and we where allowing code out that in most cases was on it's first build!! and every time it was working perfectly. It turns out the 'Jeff' realised that he could effectively "Mistake proof" 95% of all these issues by wrapping everything in a try/catch block, and effectively nullifying the error condition. To him, this was a win/win situation, he was in full belief that the whole purpose of try/catch was for this very purpose (Apparently that's what his boss a senior dev, had taught him try/catch was for) (This was the same boss who also was proud of the fact that he shoe horned the last round of functionality into said product over a weekend without any bugs or issues) The net result as you can imagine however, was that in a lot of really weird edge cases some things wouldn't work, or there would be bugs that the dev team just couldn't replicate. It wasn't until my team started to look at 'Jeff's' commit logs and examine his patches that we realised what was happening. Now the kick in the teeth, this kind of scenario happens way more than you might think, esp where you have non technical managers , managing the roll out. As far as @David's comments go, mistake-proofed code is well written to start with, good design patterns, and all that jazz make sure that things are done correctly. I will however add to that, proper debugging and integration testing is also critical. TDD does help also, but do I trust it 100% no, I'll still always try to go through every line of code and test it myself personally. Lastly however, one final statement, you are never ever going to make any piece of code 100% bullet proof, there will always be one idiot that will try to make the app do something so totally upside down, that an edge case you never even though of will come to light. oh and when you do find that Idiot... make sure you hire him as your lead tester!12 days ago ZijianZijian H. • Yes, Peter, common story in IT. Jeff got praised, and then promoted becoming your manager. Then you suffer since you have to leave, then the customers suffer since they get doggy products with these bug fixes; then the company suffers since the customers desert the company; then Jeff moves on to the other company as a manager ...12 days ago ZijianZijian H. • I mentioned I prefer Defensive Programming over Mistake Proofing, however, I think Mistake Proofing may be sexier, more appealing to non-tech manager and Jeff who had become manager.12 days ago FranckFranck M. • I praise myself in having a large proportion of computer illiterate clients, and believe me there, they are the best a developer can dream of in term of "mistake-proofing" code. If anything has to go wrong, they will fall on it, and keep banging on it until it is fixed! I try to stay away as possible from try/catch for anything I publish, and every user action is filtered through...12 days ago ThomasThomas T. • @Peter... coding empty catch blocks?!? (Did you know we can radically reduce the number of calls coming into a 9-1-1 call center? Let's just turn off the phone system...) Our virtual Jeff wasn't Mistake-Proofing. He was at best misappropriating the term while really just sweeping problems under the rug. And woe be unto the shop that endorsed that practice without instituting some level of review... it deserves all the bad juju coming its way (though, sadly, it's seldom the management that pays the full brunt of the price.) Mistake-proofing can't really be defined so much by concrete terms ("defensive programming + OOP") as it can in the abstract. Mistake-proofing is embodied by developer attitude -- a "not on my watch" proactive attitude to preventing future bugs -- and a considered competence in properly knowing what is good and not good. It is Design with Forethought, making code easy to use and hard to abuse, not knee-jerk application of marginally appropriate coding constructs. I think we can agree that what Jeff was doing was *not* Mistake-proofing, but rather Mistake-sanctioning. It's just too bad that it wasn't recognized as such in a timely fashion. I'm guessing that the take-away is that Mistake-Proofing (a good thing) needs to exist at more levels of the organization than just the interface between developer and keyboard. Semper Vigilans.12 days ago PeterPeter S. • @Thomas - absolutely spot on, but "Jeff" in all honesty believed what he was doing was "Mistake Proofing" , he genuinely believed what he was doing was a good thing, even after we realised what he was doing, and after many of the guys on my team pointed out to him just how bad what he was doing was, he still had an innate belief that it was a good thing he was doing. Needless to say, I lasted there about another 2 weeks, before some "Internal Politically Motivated Reason" was found to suspend my contract. Shortly thereafter many of my team mates where also "Politically Engineered" out of the equation. What happened to "Jeff" I really don't know, but said company has Elmah enabled publicly, and the global password to get in still works, and well..... I'm not even going to comment on what I can see :-) none of the code my team wrote ever got used however, that much I do know.12 days ago NickNick R. • What I like about that quote from Mary and Tom Poppendieck is that it can apply to so many phases of software development. Making something mistake-proof can mean not allowing the end customer to bring the system down unintentionally--not allowing them to shoot themselves in the foot. That sort of defensive programming may exist more at the UI level. But what's really interesting to me is mistake-proofing code in the business layer so that the next developer that uses a class I've created, they can't get it wrong. This is in the spirit of making a straighforward API, where how to use it is not ambiguous. A big advantage to mistake-proofing is that you know for certain: There's no way the end user (or developer) could use this (class) incorrectly! Therefore, we can do away with all of that extra integration testing. So this has a real potential for saving time!12 days ago MaxMax G. • Do the things you listed. In addition, do these: 1. Use good designs to make it obvious where changes should go. 2. Use test-driven development at multiple levels of granularity. 3. Refactor regularly to keep your design and tests good. Good design has these properties: 1. Concise - Nothing is duplicated. 2. Cohesive - Unrelated things do not share a container. 3. Abstracted - Variations are hidden behind interfaces. 4. Decoupled - It is difficult to couple to implementation details but easy to get needs fulfilled. All of these things are just special cases of the over-arching design principle: encapsulation. Design patterns are pearls of wisdom on how to get good designs. TDD should be applied at the following levels: 1. Unit/Behavior - Test the individual behaviors that live in each class and the relationships between classes. 2. Integration/Feature/Functional - Test how the parts of your system work together but still factor out things like databases. 3. Acceptance/Value - Test that the whole system or collection of systems provides the user- or customer-value that it should. Each of your tests then serves as a specification. Don't trust anyone who says "you only need integration tests". That's either inexperience or a need to justify some bad design decisions talking. Typically the latter. It's most important to have acceptance tests but it's also the hardest to implement. Start with unit tests. A year or two down the line, go to the functional tests. Then, after another couple years, add in the acceptance tests. That seems to work. Use the same kind of phased roll out plan for design patterns. Start with the simplest, highest impact ones (Strategy, State, and Template Method). Get good at identifying problems where those apply. Then, when that set of skills is solid, build on them with some more patterns.12 days ago ZijianZijian H. • I think the most important to Mistake-proofing is attitude. We human make mistakes often, and all these best practices and methodologies were designed to minimize mistakes and minimize the impact of mistakes. We have better realize the limitation of wetware, and continue to study patterns / anti patterns, and improve practices.One of the problems of Jeff is that he believed he had found a silver bullet of solving every bugs, in the case mentioned above, it was try/catch blocks everywhere; in the other cases, the silver bullet could be TDD, Scrum, Lean, Agile, Defensive Programming, or Mistake Proofing. Surely the fundamental problem behind Jeff's is the organization culture.12 days ago PeterPeter L. • "Try ... Catch ... Do nothing" is the modern way ... but it lacks the cachet of the Oh so popular "On Error Continue"12 days ago MaxMax G. • @Peter: That's hilarious. I love it.12 days ago PeterPeter L. • @Nick ... I don't treat what you have described as "mistake-proofing". As far as I am concerned, any method that crashes because of its input is way, way sub-standard. This is testing. This is debugging. This is QA. This is normal development. It is not "mistake-proofing". Secondly ... "do away with integration testing" ... rubbish ! Imagine a method which calculates the number of working days between two dates. A developer uses this to calculate interest on borrowed funds. The unit test is perfect. By your reckoning that is the end of the story. However, had the integration test been done, the bank would notice that it was lending money for nothing over the Easter period. @Max ... continuing on from the above ... I go the other way. The *only* testing I do is integration/systems testing. The system-level tests must, of course, exercise all the moving parts within the method. Having met this objective, I fail to see what benefit there was to anybody by having also unit-level tested prior yo system-level testing.12 days ago MaxMax G. • @Peter: Unit testing is easy to grasp, easy to get benefit from, and indispensable anyway. A proper suite of unit tests specifies exactly how every class (save for the occasional facade over an external system) behaves and provides feedback on whether or not a system's parts are working in seconds. Integration tests do no such thing. They provide also invaluable feedback on whether the moving parts work together but, by their very nature, they must test multiple behaviors at the same time. This means that you end up with a lot of coupling between tests - often needing to change many tests for one simple modification of behavior. With unit tests done correctly, you can isolate each and every behavior so that it has one test and only one test. Sure, there's a small class of things that require you to change more than one test like modifying an interface, but for the most part you can focus only on the behavior you want to modify. That same force helps you keep your design at the correct level of cohesion. People who only do integration testing often end up with sub-par designs because they aren't getting feedback from their tests on their design.12 days ago NickNick R. • This discussion is really getting to the heart of it. Do we put all of our efforts into testing--integration mainly, because that's what you have to do when you don't trust the components you're using--or into making testing superfluous because those components can't be used incorrectly? Integration testing takes a lot of time. It's billable man hours. And you have to do it all over again each time you use the component in another part of the code.Mistake proofing means eliminating all of that wasted time, no? With proper unit testing of course. These components can't be used wrongly.12 days ago ZijianZijian H. • Unit tests can be used against your codes as well as 3rd .net components of which you have no source code. Yes, you shouldn't trust the 3rd components, just as you shouldn't trust your own codes. Please refer to my recent post "Google is your alcoholic friend" at http://webandlife.blogspot.com.au/2012/11/google-is-your-alcoholic-friend.htmlDepend on the types of integration tests, with proper project management, most integration tests may be automated, with the assistant of ms test, nunit or other more dedicated integration test frameworks. From my personal experience, 1 hour you spent on testing could save you at least 2 hours in debugging.12 days ago TrevorTrevor L. • Hi Nick, "This discussion is really getting to the heart of it. Do we put all of our efforts into testing--integration mainly, because that's what you have to do when you don't trust the components you're using--or into making testing superfluous because those components can't be used incorrectly? " I am not sure anyone insinuated that we use "mistake proofing" to eliminate testing. I think there is a difference between "inspection" (the word used in the original article; and "testing". We arrive at mistake proofed code; if we can by thorough testing. We think of all of the ways that it can be incorrectly used, then we test to make sure we have closed all of those methods. Like David H, I can see places where I would like to use an anemic object model. There is in assence nothing wrong with that used in the right place. I also like your idea of not using public when private will do. On that principle you might like to also consider only writing sealed classes. If however you intend your class to be a base class then make it abstract. Could you imagine an API fine tuned to such a degree that sealed and abstract are the only class types used? That must help.12 days ago PeterPeter L. • @Max ... you missed the fine print of my comments if you can say that ubit testing is indispensable because system testing doesn't give us proper coverage. The fine print lies in the meaning of "moving part". Simply stated, when all of the moving parts within a method have been exercised, then each and every line and symbol will have been proven. And yes, what you said I agree with (except that you frown and I smile) ... one system test covers hundreds of itty bitty unit tests in one fell swoop. Little ripper ! Zijian is correct ... system-level testing is capable of being automated. I am a tad surprised that this comment even needed to be made. How is it possible to work with automated unit tests and not notice that system-level testing can be automated? @Nick ... re " because those components can't be used incorrectly" ... you evidently didn't read my 2nd paragraph re charging zero interest over Easter. The world's most savagely proved method - which absolutely, positively cannot be broken (and I have owned many of these) can still be misused ... as in zero interest over Easter (Repeating myself - gotta stop doing that. Repeating myself - gotta stop doing that) The Lander method is tried and tested over far too many years to count. It has a simple premise. It says "if you test the function's moving parts at the same time as you test the way that the function is being used bi its invokers, then you have saved yourself wasted time and your boss large chunks of the folding green that's seldom seen"11 days ago NickNick R. • @Zijian, I'm familiar with test automation. Where I currently work, we use various types of automation to run our unit, integration and acceptance tests. I disagree that we should be unit testing third party code, though. That code should have already been unit tested by the company that created it. The entire system should, IMHO, be acceptance tested. @Trevor I'm a huge proponent of testing--just not integration testing. Now, in some cases, such as Peter's, I think that when someonesays that they had intended to create an integreation test, they had truly intended to make an integration test! However, often I see code that intended to be a unit test, but only because the developer didn't properly mock out the class's dependencies, it is in fact an integration test. But if I were to give what I believe is the definition of an integration test in its truest form, it would be a test where the interaction between classA and classB is tested. So if classA can't possible put classB into a bad state (such as by not setting required fields, etc.), then what reason is there to test that interaction? (Granted, this is a perfect-world scenario. Some interactions will need to be tested, such as those that would cause a runtime exception, like throwing exception for null arguments.) Eliminating needless integration testing would, if I am more realistic about it, be more of a goal than an absolute. Wouldn't mistake proofing help us towards that goal? @Peter, sorry I have to plead ignorance on the interest over Easter thing. I read that, but didn't really understand the business rule. I'm not a math person or a banking person! But could that business rule be hidden in the private logic of the InterestCalculator class? And after being unit tested, could we say, "That rule is something that the end user (developer) will never need to concern themselves with. The InterestCalculator has the smarts to deal with it internally."? To go a bit further, is it possible to mistake proof the InterestCalculator so that the developer can't run into this Easter problem? Forgive me if I'm totally missing it here.11 days ago Follow PeterPeter Lander • @Nick ... indeed you are totally missing it. The working days calculator treats Easter as non-working days. The interest calculator author mistakenly used this function to calculate the number of elapsed days. Zero days is zero dollars. And the problem does not lie in the quality of the unit tested days calculator ... it lies in its misuse in a function that must not use it. As far as the idea of mistake-proofing the interest calculator goes ... if you inspect your reasoning carefully, you have noticed that having failed to tackle the problem at level(1) you have merely hopped up to level(2). At level(2) exactly the same problem arises. Suppose I wrote the interest calculator to compute at monthly rests. The person misusing it applied it to an environment where daily rests (or even Japanese hourly rests) was the requirement. A good method being misused. And, of course, we could step up to level(3) in a sort of infinite recursion ... but why? The assertion is "100% excellent and proven methods can be misused". To be honest, I think it is self-evident.11 days ago• Like Follow NickNick Ramirez • @Peter, now I'm up to speed on what you're saying. So this developer is using the wrong tool for the job. You're right. Mistake proofing will not guard against someone using a class in a situation that it was not designed for. No more than using an electrical cable as fishing line will give the desired result. It will, however, guard against people using it in the correct situation, but using it wrongly--such as not setting the state of the class correctly (or trying to plug a cable into an electrical socket upside down). How would we prevent the error condition you've described? Probably an integration test. Or acceptance tests. This is all granted you're testing for the correct error condition! But yes, some things just need to be tested out. Acceptance testing is my preferred method because you'd be explicitly testing the entire system against some expected outputs. What mistake proofing does is narrow the area where these mistakes can happen. Going back to the electrical cable example, without mistake proofing, let's say that the user had to assemble the wire themselves before using. Such as: they have to attach the pieces of the plug together before inserting the plug into the wall. Some people may get it right. Others might attach it upside down. This analogy is akin to a class that is willy-nilly with who can set its state. If all properties are public, or if we're allowing ambiguity to seep into how a class should be used (nullable integers, too many overloads, ambiguous method names, lack of encapsulation of lower level interfaces), then more errors are sure to come. As the rate of errors drops because of mistake proofing, developers should feel confident writing fewer integration tests.11 days ago• Like Follow TysonTyson Wolker • Code Complete is a great read and discusses "Defensive Programming". Must read book, it will probably answer the question better than I could. Mistake proofing code is not an easier requirement and typically would involve having others inspect your code. At the end of the day the most simplest code can still be prone to bugs that you may not think of on that day. Any quality improvement techniques related to code can help to solidify defensive programming.Unit testing, if you make great test cases and have unit testing the function will 'always' achieve its desired result or most the time raise red flags showing that something has been broken. At the end of the day you don't want to make too brittle code either. Typically my understanding to defensive programming is check every possible scenario, throw exceptions when an undesirable result is achieved.Programming too defensive can be a negative too, as there are more conditions to check for and may have performance implications (very minimal) among other things.http://yikliu.wordpress.com/2011/01/21/code-complete-ch-8-defensive-programming/The above is a good summary of Code Complete's chapter of defensive programming.11 days ago• Like Follow PeterPeter Lander • @Nick ... re-read everything I have said. Then imagine yourself actually doing it. You will see that what I call system-level testing and what you and most others call "integration" testing - when it is done the Lander way - is the only testing that needs to be done. You admire the way that unit testing reduces the load on systems testing. I admire the way that my systems testing eliminates the need for unit testing. I will relate a true story ... so long ago that it should start with "Once upon a time" ... Our PM demanded that we build from the top down. The terminology didn't even really exist when he said this. Half a dozen of us spent the first 3 months of a 9 month project getting a big heap of "stubs" set up. And building a defined but empty database. At the 1/3rd point his boss asked how we were going. He said "we can now do nothing to no data". From that day onward, each day saw the remaining most important stubs get coded and tested ... and each and every test (thousands of them) was system level testing. At the end of 9 months, the remaining stubs were of trivial consequence. His boss said "time is up" and we handed over a system - that same afternoon - that had been "integration" tested to death ... and one which had its "wish list" completely mapped out. Cost and time 100% perfect. Definitely beer o'clock. I didn't reach my Lander method casually or theoretically ... I got there the hard way. It works.10 days ago• Like Follow ZijianZijian Huang • There are many methodologies and practices approaching mistake proofing. They all worked, and will be working within certain contexts. In contrast, haven't we seen enough examples of such culture: one size fits all; or cut your toes to fit the shoe?- NUnit is like testing the foundations of the house and the rooms are built to the correct size - Fitnesse is testing whether the wiring between the rooms is correct and whether the water pumps correctly throughout the house - Selenium checks that the bedroom is comfortable and that the living room has the TV in the right spot. 